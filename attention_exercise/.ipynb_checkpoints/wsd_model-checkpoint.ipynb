{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import data_loader\n",
    "from traineval import train, evaluate\n",
    "import model as model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "The following line of code invokes data_loader and will automatically download and extract the dataset if needed.\n",
    "It instantiates the following variables;\n",
    "* tokens_vocab - the sentence words vocabulary\n",
    "* y_vocab - the labels (senses) vocabulary\n",
    "* datasets - a dictionary with train,dev, and test WSDDataset instances.\n",
    "\n",
    "Use the optional sentence_count kwarg to limit the number of sentences loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, tokens_vocab, y_vocab = data_loader.load_train_dataset(sentence_count=1000)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = data_loader.load_dev_dataset(tokens_vocab, y_vocab, sentence_count=100)\n",
    "dev_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Query-Based Attention\n",
    "\n",
    "Implement the model.\n",
    "\n",
    "Load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.25\n",
    "D = 300\n",
    "\n",
    "m = model.WSDModel(\n",
    "    tokens_vocab.size(), \n",
    "    y_vocab.size(), \n",
    "    D=D, \n",
    "    dropout_prob=dropout\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 8e-5\n",
    "batch_size=100\n",
    "num_epochs=10\n",
    "\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "\n",
    "losses, train_acc, val_acc = train(\n",
    "    m, optimizer, train_dataset, dev_dataset, num_epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "print(f\"Validation accuracy: {val_acc[-1]:.3f}, Training accuracy:{train_acc[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and training/validation accuracy. You should be getting ~54% validation accuracy after 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
    "\n",
    "axs[0].plot(losses, '-', label='Train Loss');\n",
    "axs[0].legend()\n",
    "axs[1].plot(train_acc, '-o', label='Train Acc');\n",
    "axs[1].plot(val_acc, '-o', label='Val Acc');\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the attention vizualization to get a feel of what the model is attending to.\n",
    "\n",
    "The query token is highlighted in green, and the model's attention with a pink-blue gradient.\n",
    "In addition, the loss is given a red gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traineval import higlight_samples\n",
    "\n",
    "higlight_samples(m, dev_dataset, sample_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Padding\n",
    "\n",
    "Implement the padding mask.\n",
    "\n",
    "Load the model and retrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model.WSDModel(\n",
    "    tokens_vocab.size(), \n",
    "    y_vocab.size(), \n",
    "    D=D, \n",
    "    dropout_prob=dropout\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "\n",
    "losses, train_acc, val_acc = train(\n",
    "    m, optimizer, train_dataset, dev_dataset, num_epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and training/validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
    "\n",
    "axs[0].plot(losses, '-', label='Train Loss');\n",
    "axs[0].legend()\n",
    "axs[1].plot(train_acc, '-o', label='Train Acc');\n",
    "axs[1].plot(val_acc, '-o', label='Val Acc');\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the visualization to verify that the model does not attend on pads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higlight_samples(m, dev_dataset, sample_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine additional examples, using the API and pandas as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from traineval import evaluate_verbose, highlight\n",
    "\n",
    "pd.set_option('max_columns', 100)\n",
    "\n",
    "eval_df, attention_df = evaluate_verbose(m, dev_dataset, iter_lim=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of 5 incorrectly classified examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.where(eval_df['y_true'] != eval_df['y_pred'])\n",
    "idxs = list(idxs[0][:5])\n",
    "highlight(eval_df, attention_df, idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of examples with the query word \"left\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.where(eval_df['query_token'] == 'left')\n",
    "highlight(eval_df, attention_df, idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Self-Attention\n",
    "\n",
    "The method below converts the query-based instances in WSDDataset to sentence-level instances in WSDSentencesDataset for self-attention.\n",
    "\n",
    "Notice how the number of samples now equals number of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_train_dataset = data_loader.WSDSentencesDataset.from_word_dataset(train_dataset)\n",
    "sa_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_dev_dataset = data_loader.WSDSentencesDataset.from_word_dataset(dev_dataset)\n",
    "sa_dev_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement self-attention in the model.\n",
    "\n",
    "Load the model and retrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=2e-4\n",
    "dropout = 0.2\n",
    "D=300\n",
    "batch_size=100\n",
    "num_epochs=5\n",
    "\n",
    "m = model.WSDModel(\n",
    "    tokens_vocab.size(), \n",
    "    y_vocab.size(), \n",
    "    D=D, \n",
    "    dropout_prob=dropout\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
    "\n",
    "losses, train_acc, val_acc = train(\n",
    "    m, optimizer, sa_train_dataset, sa_dev_dataset, num_epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and training/validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
    "\n",
    "axs[0].plot(losses, '-', label='Train Loss');\n",
    "axs[0].legend()\n",
    "axs[1].plot(train_acc, '-o', label='Train Acc');\n",
    "axs[1].plot(val_acc, '-o', label='Val Acc');\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Position-Sensitive Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your experiments here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Causal Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your experiments here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tau_nlp",
   "language": "python",
   "name": "tau_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
